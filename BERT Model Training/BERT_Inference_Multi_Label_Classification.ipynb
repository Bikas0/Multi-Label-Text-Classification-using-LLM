{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# https://www.kaggle.com/code/bikasuzzaman/multil-label-text-classification/output"
      ],
      "metadata": {
        "id": "MA365A9ixwYk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import numpy as np\n",
        "import torch\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "SEFfKGghzqYT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTClass, self).__init__()\n",
        "        self.bert_model = BertModel.from_pretrained('bert-base-uncased', return_dict=True)\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "        self.linear = torch.nn.Linear(768, 8)\n",
        "\n",
        "    def forward(self, input_ids, attn_mask, token_type_ids):\n",
        "        output = self.bert_model(\n",
        "            input_ids,\n",
        "            attention_mask=attn_mask,\n",
        "            token_type_ids=token_type_ids\n",
        "        )\n",
        "        output_dropout = self.dropout(output.pooler_output)\n",
        "        output = self.linear(output_dropout)\n",
        "        return output\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLrrhyap0F8W",
        "outputId": "56a9ce12-a9e8-435d-8901-4d310092d40a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "MAX_LEN = 256\n",
        "THRESHOLD = 0.5 # threshold for the sigmoid\n",
        "# Loading pretrained model (best model)\n",
        "model = BERTClass()\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/ph3_model/MLTC_model_state.bin\"))\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "_8V_7aKJ0nix"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# raw text\n",
        "raw_text = \"\"\"\n",
        "\n",
        "১০০% আসল প্রোডাক্ট। সিলেটের মধ্যে ৮ দিনের মধ্যে ডেলিভারি হয়েছে। বিক্রেতা খুবই সহানুভূতিশীল এবং ভালো ছিলেন। এই প্রোডাক্টটি এই বিক্রেতার কাছ থেকে কেনার জন্য অত্যন্ত সুপারিশ করছি।\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Q2hfjoCC008c"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_text = tokenizer.encode_plus(\n",
        "    raw_text,\n",
        "    max_length=MAX_LEN,\n",
        "    add_special_tokens=True,\n",
        "    return_token_type_ids=True,\n",
        "    pad_to_max_length=True,\n",
        "    return_attention_mask=True,\n",
        "    return_tensors='pt',\n",
        ")\n",
        "\n",
        "input_ids = encoded_text['input_ids'].to(device)\n",
        "attention_mask = encoded_text['attention_mask'].to(device)\n",
        "token_type_ids = encoded_text['token_type_ids'].to(device)\n",
        "output = model(input_ids, attention_mask, token_type_ids)\n",
        " # add sigmoid, for the training sigmoid is in BCEWithLogitsLoss\n",
        "output = torch.sigmoid(output).detach().cpu()\n",
        "# thresholding at 0.5\n",
        "output = output.flatten().round().numpy()\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8cbrGQR1QS7",
        "outputId": "7615016a-61f8-4346-9059-82b8f5b4e28a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2699: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 1., 0., 1., 0., 0., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Correctly identified the topic of the paper: High energy physics\n",
        "target_list = ['price',\n",
        " 'packaging',\n",
        " 'product',\n",
        " 'rider',\n",
        " 'delivery',\n",
        " 'shelf',\n",
        " 'service',\n",
        " 'seller']\n",
        "\n",
        "print(f\"Title: {raw_text}\")\n",
        "for idx, p in enumerate(output):\n",
        "    if p==1:\n",
        "        print(f\"Label: {target_list[idx]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azCv_cJc1UBz",
        "outputId": "95883f67-e3d6-4c6e-b898-5bf98fa2121f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: \n",
            "১০০% আসল প্রোডাক্ট। সিলেটের মধ্যে ৮ দিনের মধ্যে ডেলিভারি হয়েছে। বিক্রেতা খুবই সহানুভূতিশীল এবং ভালো ছিলেন। এই প্রোডাক্টটি এই বিক্রেতার কাছ থেকে কেনার জন্য অত্যন্ত সুপারিশ করছি।\n",
            "\n",
            "Label: product\n",
            "Label: delivery\n",
            "Label: seller\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xw7lmTLs1X0a"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}